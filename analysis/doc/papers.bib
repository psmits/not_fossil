@article{Aitchison2005,
abstract = {We take stock of the present position of compositional data analysis, of what has been achieved in the last 20 years, and then make suggestions as to what may be sensible avenues of future research. We take an uncompromisingly applied mathematical view, that the challenge of solving practical problems should motivate our theoretical research; and that any new theory should be thoroughly investigated to see if it may provide answers to previously abandoned practical considerations.},
author = {Aitchison, J. and {J. Egozcue}, J.},
doi = {10.1007/s11004-005-7383-7},
file = {:home/peter/Documents/Mendeley Desktop/Aitchison, J. Egozcue/Mathematical Geology/Aitchison, J. Egozcue - 2005 - Mathematical Geology.pdf:pdf},
isbn = {0882-8121},
issn = {0882-8121},
journal = {Mathematical Geology},
keywords = {hilbert and euclidean space,regression,sample,simplex geometry,space,stay-in-the-simplex,subcomposition},
number = {7},
pages = {829--850},
title = {{Compositional Data Analysis: Where Are We and Where Should We Be Heading?}},
url = {http://link.springer.com/10.1007/s11004-005-7383-7},
volume = {37},
year = {2005}
}
@article{Aitchison1982,
abstract = {The simplex plays an important role as sample space in many practical situations where compositional data, in the form of proportions of some whole, require interpretation. It is argued that the statistical analysis of such data has proved difficult because of a lack both of concepts of independence and of rich enough parametric classes of distributions in the simplex. A variety of independence hypotheses are introduced and interrelated, and new classes of transformed-normal distributions in the simplex are provided as models within which the independence hypotheses can be tested through standard theory of parametric hypothesis testing. The new concepts and statistical methodology are illustrated by a number of applications.},
author = {Aitchison, John},
doi = {10.2307/2345821},
file = {:home/peter/Documents/Mendeley Desktop/Aitchison/Journal of the Royal Statistical Society. Series B. Methodological/Aitchison - 1982 - Journal of the Royal Statistical Society. Series B. Methodological.pdf:pdf},
isbn = {00359246},
issn = {0035-9246},
journal = {Journal of the Royal Statistical Society. Series B. Methodological},
number = {2},
pages = {139--177},
pmid = {1043},
title = {{The Statistical Analysis of Compositional Data}},
url = {http://links.jstor.org/sici?sici=0035-9246(1982)44:2{\%}3C139:TSAOCD{\%}3E2.0.CO{\%}5Cn2-9{\&}origin=MSN{\%}5Cnpapers2://publication/uuid/D7E07C14-661F-49B0-B887-CFF0DCF0F38A},
volume = {44},
year = {1982}
}
@article{Aitchison,
abstract = {Compositional data consisting of vectors of positive components subject to a unit-sum constraint arise in many disciplines, for example in geology as major-oxide compositions of rocks, in economics as budget share patterns of household expenditures, in medicine as compositions of renal calculi, in psychology as activity patterns of subjects. 'Standard' multivariate techniques, designed for unconstrained data, are wholly inappropriate and uninterpretable for such data and yet are still being commonly misapplied. Recognition that the study of compositions must satisfy simple principles has led recently to the advocacy of new forms of analysis of compositional data. The nature of the absurdities arising from applying traditional multivariate techniques to compositions is briefly highlighted and a description of the essential aspects and the advantages of the new methodology is provided.},
author = {Aitchison, John},
doi = {10.2307/4355794},
file = {:home/peter/Documents/Mendeley Desktop/Aitchison/CDA Workshop Girona/Aitchison - 2002 - CDA Workshop Girona.pdf:pdf},
isbn = {9781930665781},
issn = {07492170},
journal = {CDA Workshop Girona},
pages = {73--81},
title = {{A Concise Guide to Compositional Data Analysis}},
url = {http://www.leg.ufpr.br/lib/exe/fetch.php/pessoais:abtmartins:a{\_}concise{\_}guide{\_}to{\_}compositional{\_}data{\_}analysis.pdf},
volume = {24},
year = {2002}
}
@article{Betancourt2013,
abstract = {Hierarchical modeling provides a framework for modeling the complex interactions typical of problems in applied statistics. By capturing these relationships, however, hierarchical models also introduce distinctive pathologies that quickly limit the efficiency of most common methods of in- ference. In this paper we explore the use of Hamiltonian Monte Carlo for hierarchical models and demonstrate how the algorithm can overcome those pathologies in practical applications.},
archivePrefix = {arXiv},
arxivId = {1312.0906},
author = {Betancourt, M. J. and Girolami, Mark},
doi = {10.1201/b18502-5},
eprint = {1312.0906},
file = {:home/peter/Documents/Mendeley Desktop/Betancourt, Girolami/arXiv/Betancourt, Girolami - 2013 - arXiv.0906v1:0906v1},
isbn = {9761482235111},
journal = {arXiv},
title = {{Hamiltonian Monte Carlo for Hierarchical Models}},
url = {http://arxiv.org/abs/1312.0906},
year = {2013}
}
@article{StanPaper,
abstract = {Stan is a probabilistic programming language for specifying statistical models. A Stan program imperatively defines a log probability function over parameters conditioned on specified data and constants. As of version 2.14.0, Stan provides full Bayesian inference for continuous-variable models through Markov chain Monte Carlo methods such as the No-U-Turn sampler, an adaptive form of Hamiltonian Monte Carlo sampling. Penalized maximum likelihood estimates are calculated using optimization methods such as the limited memory Broyden-Fletcher-Goldfarb-Shanno algorithm. Stan is also a platform for computing log densities and their gradients and Hessians, which can be used in alternative algorithms such as variational Bayes, expectation propagation, and marginal inference using approximate integration. To this end, Stan is set up so that the densities, gradients, and Hessians, along with intermediate quantities of the algorithm such as acceptance probabilities, are easily accessible. Stan can be called from the command line using the cmdstan package, through R using the rstan package, and through Python using the pystan package. All three interfaces support sampling and optimization-based inference with diagnostics and posterior analysis. rstan and pystan also provide access to log probabilities, gradients, Hessians, parameter transforms, and specialized plotting.},
author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
doi = {10.18637/jss.v076.i01},
file = {:home/peter/Documents/Mendeley Desktop/Carpenter et al/Journal of Statistical Software/Carpenter et al. - 2017 - Journal of Statistical Software.pdf:pdf},
issn = {1548-7660},
journal = {Journal of Statistical Software},
number = {1},
title = {{Stan : A Probabilistic Programming Language}},
url = {http://www.jstatsoft.org/v76/i01/},
volume = {76},
year = {2017}
}
@article{Egozcue2003,
abstract = {Geometry in the simplex has been developed in the last 15 years mainly based on the contributions due to J. Aitchison. The main goal was to develop analytical tools for the statistical analysis of compositional data. Our present aim is to get a further insight into some aspects of this geometry in order to clarify the way for more complex statistical approaches. This is done by way of orthonormal bases, which allow for a straightforward handling of geometric elements in the simplex. The transformation into real coordinates preserves all metric properties and is thus called isometric logratio transformation (ilr). An important result is the decomposition of the simplex, as a vector space, into orthogonal subspaces associated with nonoverlapping subcompositions. This gives the key to join compositions with different parts into a single composition by using a balancing element. The relationship between ilr transformations and the centered-logratio (clr) and additive-logratio (alr) transformations is also studied. Exponential growth or decay of mass is used to illustrate compositional linear processes, parallelism and orthogonality in the simplex.},
author = {Egozcue, J. J. and Pawlowsky-Glahn, V. and Mateu-Figueras, G. and Barcel{\'{o}}-Vidal, C.},
doi = {10.1023/A:1023818214614},
file = {:home/peter/Documents/Mendeley Desktop/Egozcue et al/Mathematical Geology/Egozcue et al. - 2003 - Mathematical Geology.pdf:pdf},
isbn = {0882-8121},
issn = {08828121},
journal = {Mathematical Geology},
keywords = {Aitchison distance,Aitchison geometry,Geodesic,Orthogonal subcompositions,Ternary diagram},
number = {3},
pages = {279--300},
pmid = {21314881},
title = {{Isometric Logratio Transformations for Compositional Data Analysis}},
volume = {35},
year = {2003}
}
@book{BDA3,
address = {Boca Raton, FL},
author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
edition = {3rd},
publisher = {CRC Press},
title = {{Bayesian Data Analysis}},
year = {2014}
}
@book{ARM,
address = {Cambridge},
author = {Gelman, Andrew and Hill, Jennifer},
publisher = {Cambridge University Press},
title = {{Data Analysis Using Regression and Multilevel/Hierarchical Models}},
year = {2006}
}
@article{Gelman2008,
archivePrefix = {arXiv},
arxivId = {arXiv:0901.4011v1},
author = {Gelman, By Andrew and Jakulin, Aleks and Pittau, Maria Grazia and Su, Yu-Sung},
doi = {10.1214/08-AOAS191},
eprint = {arXiv:0901.4011v1},
file = {:home/peter/Documents/Mendeley Desktop/Gelman et al/The Annals of Applied Statistics/Gelman et al. - 2008 - The Annals of Applied Statistics(2).pdf:pdf},
journal = {The Annals of Applied Statistics},
keywords = {Bayesian inference,generalized linear model,hierarchical model,least squares,linear regression,logistic regression,multilevel model,noninformative prior distribution,weakly informative prior distribution},
number = {4},
pages = {1360--1383},
title = {{A weakly informative default prior distribution for logistic and other regression models}},
volume = {2},
year = {2008}
}
@article{Hron2012,
abstract = {In disease screening and diagnosis, often multiple markers are measured and they are combined in order to improve the accuracy of diagnosis. McIntosh and Pepe (2002, Biometrics58, 657-644) showed that the risk score, Compositional explanatory variables should not be directly used in a linear regression model because any inference statistic can become misleading. While various approaches for this problem were proposed, here an approach based on the isometric logratio (ilr) transformation is used. It turns out that the resulting model is easy to handle, and that parameter estimation can be done in like in usual linear regression. Moreover, it is possible to use the ilr variables for inference statistics in order to obtain an appropriate interpretation of the model.},
archivePrefix = {arXiv},
arxivId = {arXiv:1401.7168v1},
author = {Hron, K. and Filzmoser, P. and Thompson, K.},
doi = {10.1080/02664763.2011.644268},
eprint = {arXiv:1401.7168v1},
file = {:home/peter/Documents/Mendeley Desktop/Hron, Filzmoser, Thompson/Journal of Applied Statistics/Hron, Filzmoser, Thompson - 2012 - Journal of Applied Statistics.pdf:pdf},
issn = {02664763},
journal = {Journal of Applied Statistics},
keywords = {Aitchison geometry on the simplex,isometric logratio transformation,mixtures,orthonormal coordinates},
number = {5},
pages = {1115--1128},
pmid = {20161201},
title = {{Linear regression with compositional explanatory variables}},
volume = {39},
year = {2012}
}
@article{Peters2018,
author = {Peters, Shanan E and Husson, Jon M and Czaplewski, John J},
doi = {http://doi.org/10.17605/OSF.IO/YNAXW},
file = {:home/peter/Documents/Mendeley Desktop/Peters, Husson, Czaplewski/EarthArXiv/Peters, Husson, Czaplewski - 2018 - EarthArXiv.pdf:pdf},
journal = {EarthArXiv},
keywords = {application pro-,earth system science,geological synthesis,relational databases},
title = {{Macrostrat: a platform for geological data integration and deep-time Earth crust research}},
url = {https://eartharxiv.org/ynaxw},
year = {2018}
}
@article{Peters2016,
abstract = {The Paleobiology Database (PBDB; https://paleobiodb.org ) consists of geographically and temporally explicit, taxonomically identified fossil occurrence data. The taxonomy utilized by the PBDB is not static, but is instead dynamically generated using an algorithm applied to separately managed taxonomic authority and opinion data. The PBDB owes its existence to many individuals, some of whom have entered more than 1.26 million fossil occurrences and over 570,000 taxonomic opinions, and some of whom have developed and maintained supporting infrastructure and analysis tools. Here, we provide an overview of the data model currently used by the PBDB and then briefly describe how this model is exposed via an Application Programming Interface (API). Our objective is to outline how PBDB data can now be accessed within individual scientific workflows, used to develop independently managed educational and scientific applications, and accessed to forge dynamic, near real-time connections to other data resources.},
author = {Peters, Shanan E. and McClennen, Michael},
doi = {10.1017/pab.2015.39},
file = {:home/peter/Documents/Mendeley Desktop/Peters, McClennen/Paleobiology/Peters, McClennen - 2015 - Paleobiology.pdf:pdf},
isbn = {0094837315000},
issn = {00948373},
journal = {Paleobiology},
number = {1},
pages = {1--7},
title = {{The Paleobiology Database application programming interface}},
volume = {42},
year = {2015}
}
@misc{StanManual,
author = {Team, Stan Development},
title = {{Stan Modeling Language Users Guide and Reference Manual}},
url = {http://mc-stan.org},
year = {2017}
}
